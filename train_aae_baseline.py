"""
è®­ç»ƒAAE (Adversarial Autoencoder) Baselineæ¨¡å‹ç”¨äºä¸Diffusionæ¨¡å‹å¯¹æ¯”

AAEä½¿ç”¨å¯¹æŠ—è®­ç»ƒæ¥çº¦æŸæ½œåœ¨ç©ºé—´åˆ†å¸ƒï¼Œç›¸æ¯”VAEçš„KLæ•£åº¦çº¦æŸï¼Œ
AAEä½¿ç”¨åˆ¤åˆ«å™¨æ¥å¼ºåˆ¶æ½œåœ¨ç¼–ç ç¬¦åˆå…ˆéªŒåˆ†å¸ƒï¼ˆé€šå¸¸æ˜¯é«˜æ–¯åˆ†å¸ƒï¼‰ã€‚

ä½¿ç”¨è¯´æ˜:
    python train_aae_baseline.py --device cuda:0
    æˆ–ä½¿ç”¨CPUï¼ˆå¦‚æœGPUæœ‰é—®é¢˜ï¼‰:
    python train_aae_baseline.py --device cpu
"""

import argparse
import os
import sys
import torch
import pandas as pd
from pathlib import Path

# Add moses to path
sys.path.insert(0, str(Path(__file__).parent))

import moses
from moses.aae import AAE, AAETrainer
from moses.aae.config import get_parser


def load_moses2_data(csv_path, split='train'):
    """
    ä»moses2.csvåŠ è½½æŒ‡å®šsplitçš„æ•°æ®

    Args:
        csv_path: moses2.csvè·¯å¾„
        split: 'train', 'test', or 'test_scaffolds'

    Returns:
        list of SMILES strings
    """
    print(f"Loading {split} data from {csv_path}...")
    df = pd.read_csv(csv_path)

    if split == 'test_scaffolds':
        split_name = 'test_scaffolds'
    else:
        split_name = split

    data = df[df['SPLIT'] == split_name]['SMILES'].tolist()
    print(f"Loaded {len(data)} molecules for {split}")
    return data


def get_comparison_config(n_batch=512, lr=1e-4):
    """
    è·å–ä¸diffusionæ¨¡å‹å¯¹é½çš„AAEé…ç½®

    AAEå…³é”®å‚æ•°:
    - latent_size: 128 (ä¸diffusion hidden_dimå¯¹é½)
    - learning_rate: 1e-4 (ä¸diffusionå¯¹é½)
    - dropout: 0.1 (ä¸diffusionå¯¹é½)
    - batch_size: 512 (æŠ˜ä¸­å€¼ï¼Œdiffusionä½¿ç”¨2048)
    - è®­ç»ƒæ­¥æ•°: ~30k
    """
    # ä½¿ç”¨MOSESé»˜è®¤parseråˆ›å»ºåŸºç¡€é…ç½®
    parser = get_parser()
    config = parser.parse_args([])

    # ========== AAEå‚æ•°è®¾ç½® ==========

    # æ¨¡å‹æ¶æ„
    config.embedding_size = 32             # åµŒå…¥ç»´åº¦ (MOSESæ ‡å‡†)
    config.encoder_hidden_size = 256       # ç¼–ç å™¨éšè—å±‚
    config.encoder_num_layers = 1          # ç¼–ç å™¨å±‚æ•°
    config.encoder_bidirectional = True    # åŒå‘LSTM
    config.encoder_dropout = 0.1           # âœ… ä¸diffusionå¯¹é½

    config.latent_size = 128               # âœ… æ½œåœ¨ç»´åº¦ = diffusion hidden_dim
    config.decoder_hidden_size = 512       # è§£ç å™¨éšè—å±‚
    config.decoder_num_layers = 2          # è§£ç å™¨å±‚æ•°
    config.decoder_dropout = 0.1           # âœ… ä¸diffusionå¯¹é½

    config.discriminator_layers = [640, 256]  # åˆ¤åˆ«å™¨å±‚

    # è®­ç»ƒå‚æ•°
    config.pretrain_epochs = 0             # é¢„è®­ç»ƒè½®æ•°ï¼ˆå¯é€‰ï¼‰
    config.train_epochs = 10               # ä¸»è®­ç»ƒè½®æ•°
    config.n_batch = n_batch               # batch size
    config.lr = lr                         # âœ… å­¦ä¹ ç‡ = diffusion 1e-4

    # å­¦ä¹ ç‡è°ƒåº¦
    config.step_size = 5                   # æ¯5ä¸ªepochè¡°å‡
    config.gamma = 0.5                     # è¡°å‡å› å­0.5

    # å¯¹æŠ—è®­ç»ƒ
    config.discriminator_steps = 1         # æ¯ä¸ªè‡ªç¼–ç å™¨æ­¥éª¤è®­ç»ƒåˆ¤åˆ«å™¨1æ¬¡
    config.weight_decay = 0                # æƒé‡è¡°å‡

    # å…¶ä»–
    config.n_workers = 4
    config.n_jobs = 1
    config.save_frequency = 5              # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡

    return config


def main():
    parser = argparse.ArgumentParser(description='Train AAE Baseline for Comparison with Diffusion')

    # æ•°æ®é€‰é¡¹
    parser.add_argument('--use_moses2', action='store_true',
                        help='Use moses2.csv instead of MOSES official dataset')
    parser.add_argument('--moses2_path', type=str, default='./data/moses2.csv',
                        help='Path to moses2.csv')

    # è®­ç»ƒå‚æ•°
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='Device to use (cuda:0 or cpu)')
    parser.add_argument('--n_batch', type=int, default=512,
                        help='Batch size (256/512/1024, original AAE=512)')
    parser.add_argument('--lr', type=float, default=1e-4,
                        help='Learning rate (aligned with diffusion=1e-4)')
    parser.add_argument('--seed', type=int, default=102,
                        help='Random seed (use 102 to align with diffusion)')

    # æ¨¡å‹ä¿å­˜è·¯å¾„
    parser.add_argument('--save_dir', type=str, default='./checkpoints/aae_baseline',
                        help='Directory to save model checkpoints')
    parser.add_argument('--log_file', type=str, default='./checkpoints/aae_baseline/log.txt',
                        help='Log file path')

    args = parser.parse_args()

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        # è®¾ç½®cuDNNé…ç½®
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.benchmark = True
        print("âœ… cuDNN benchmark mode enabled")

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    # è·å–é…ç½®
    config = get_comparison_config(n_batch=args.n_batch, lr=args.lr)
    config.log_file = args.log_file
    config.model_save = os.path.join(args.save_dir, 'model.pt')
    config.config_save = os.path.join(args.save_dir, 'config.pt')
    config.vocab_save = os.path.join(args.save_dir, 'vocab.pt')

    # åŠ è½½æ•°æ®
    print("\n" + "="*60)
    print("Loading Dataset")
    print("="*60)

    if args.use_moses2:
        train_data = load_moses2_data(args.moses2_path, 'train')
        test_data = load_moses2_data(args.moses2_path, 'test')
    else:
        print("Loading MOSES official dataset...")
        train_data = moses.get_dataset('train')
        test_data = moses.get_dataset('test')
        print(f"Train: {len(train_data)}, Test: {len(test_data)}")

    # æ‰“å°é…ç½®å¯¹æ¯”
    print("\n" + "="*60)
    print("AAE Configuration (Aligned with Diffusion)")
    print("="*60)
    print(f"{'Parameter':<30} {'Value':<20} {'Note':<20}")
    print("-"*70)
    print(f"{'Model Type':<30} {'AAE':<20} {'Adversarial AE':<20}")
    print(f"{'Latent Size':<30} {config.latent_size:<20} {'âœ… = diffusion 128':<20}")
    print(f"{'Encoder Hidden':<30} {config.encoder_hidden_size:<20} {'256':<20}")
    print(f"{'Decoder Hidden':<30} {config.decoder_hidden_size:<20} {'512':<20}")
    print(f"{'Batch Size':<30} {config.n_batch:<20} {'âš ï¸ diffusion=2048':<20}")
    print(f"{'Learning Rate':<30} {config.lr:<20} {'âœ… = diffusion 1e-4':<20}")
    print(f"{'Dropout':<30} {config.encoder_dropout:<20} {'âœ… = diffusion 0.1':<20}")
    print(f"{'Seed':<30} {args.seed:<20} {'âœ… = diffusion 102':<20}")

    # è®¡ç®—è®­ç»ƒæ­¥æ•°
    steps_per_epoch = len(train_data) // config.n_batch
    total_steps = steps_per_epoch * config.train_epochs
    target_steps = 30000

    print(f"{'Steps per Epoch':<30} {steps_per_epoch:<20}")
    print(f"{'Total Epochs':<30} {config.train_epochs:<20}")
    print(f"{'Total Steps':<30} {total_steps:<20} {f'Target: {target_steps}':<20}")
    print("-"*70)

    if total_steps < target_steps * 0.8:
        print(f"âš ï¸  Warning: Total steps ({total_steps}) < target ({target_steps})")
        print(f"   Consider increasing train_epochs to {int(target_steps/steps_per_epoch) + 1}")

    # åˆ›å»ºæ¨¡å‹
    print("\n" + "="*60)
    print("Initializing Model")
    print("="*60)

    trainer = AAETrainer(config)
    vocab = trainer.get_vocabulary(train_data)
    model = AAE(vocab, config).to(args.device)

    print(f"Vocabulary size: {len(vocab)}")
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    # ä¿å­˜é…ç½®å’Œè¯æ±‡è¡¨
    torch.save(config, config.config_save)
    torch.save(vocab, config.vocab_save)
    print(f"\nâœ… Config saved to {config.config_save}")
    print(f"âœ… Vocab saved to {config.vocab_save}")

    # è®­ç»ƒ
    print("\n" + "="*60)
    print("Starting Training")
    print("="*60)
    print(f"Device: {args.device}")

    # æ‰“å°GPUä¿¡æ¯ï¼ˆå¦‚æœä½¿ç”¨CUDAï¼‰
    if args.device.startswith('cuda') and torch.cuda.is_available():
        gpu_id = int(args.device.split(':')[1]) if ':' in args.device else 0
        print(f"GPU Name: {torch.cuda.get_device_name(gpu_id)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(gpu_id).total_memory / 1024**3:.1f} GB")
        print(f"GPU Memory Allocated: {torch.cuda.memory_allocated(gpu_id) / 1024**2:.1f} MB")

    print(f"Batch size: {config.n_batch}")
    print(f"Learning rate: {config.lr}")
    print(f"Pretrain epochs: {config.pretrain_epochs}")
    print(f"Train epochs: {config.train_epochs}")
    print(f"Expected total steps: ~{total_steps}")
    print("="*60 + "\n")

    try:
        model = trainer.fit(model, train_data, val_data=test_data)

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(args.save_dir, 'model_final.pt')
        torch.save(model.state_dict(), final_model_path)
        print(f"\nâœ… Final model saved to {final_model_path}")

    except KeyboardInterrupt:
        print("\nâš ï¸  Training interrupted by user")

    except RuntimeError as e:
        print(f"\nâŒ Training failed with error: {e}")
        if "CUDA" in str(e) or "out of memory" in str(e):
            print("\nğŸ’¡ è§£å†³å»ºè®®:")
            print("1. é™ä½batch size: --n_batch 256 æˆ– --n_batch 128")
            print("2. æ¸…ç†GPUç¼“å­˜: nvidia-smi æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ")
            print("3. å°è¯•ä½¿ç”¨CPU: --device cpu")
            print(f"\nå½“å‰é…ç½®: batch_size={config.n_batch}, device={args.device}")
        raise

    except Exception as e:
        print(f"\nâŒ Training failed with error: {e}")
        raise

    print("\n" + "="*60)
    print("Training Complete!")
    print("="*60)
    print(f"\nModel checkpoints saved in: {args.save_dir}")
    print(f"Log file: {config.log_file}")
    print("\nNext steps:")
    print("1. Generate samples: python scripts/sample.py aae \\")
    print(f"   --model_load {final_model_path} \\")
    print(f"   --config_load {config.config_save} \\")
    print(f"   --vocab_load {config.vocab_save} \\")
    print("   --n_samples 10000 --gen_save ./results/aae_generated_10k.csv")
    print("2. Evaluate metrics: python evaluate_baseline.py \\")
    print("   --input ./results/aae_generated_10k.csv \\")
    print("   --output ./results/aae_baseline_metrics.txt")


if __name__ == '__main__':
    main()
