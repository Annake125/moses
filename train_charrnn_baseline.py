"""
è®­ç»ƒCharRNN Baselineæ¨¡å‹ç”¨äºä¸Diffusionæ¨¡å‹å¯¹æ¯”

CharRNNæ˜¯æœ€ç»å…¸çš„åºåˆ—ç”Ÿæˆæ¨¡å‹ï¼Œä½¿ç”¨å­—ç¬¦çº§LSTMç”ŸæˆSMILESã€‚

ä½¿ç”¨è¯´æ˜:
    python train_charrnn_baseline.py --device cuda:0
    æˆ–ä½¿ç”¨CPUï¼ˆå¦‚æœGPUæœ‰é—®é¢˜ï¼‰:
    python train_charrnn_baseline.py --device cpu
"""

import argparse
import os
import sys
import torch
import pandas as pd
from pathlib import Path

# Add moses to path
sys.path.insert(0, str(Path(__file__).parent))

import moses
from moses.char_rnn import CharRNN, CharRNNTrainer
from moses.char_rnn.config import get_parser


def load_moses2_data(csv_path, split='train'):
    """
    ä»moses2.csvåŠ è½½æŒ‡å®šsplitçš„æ•°æ®

    Args:
        csv_path: moses2.csvè·¯å¾„
        split: 'train', 'test', or 'test_scaffolds'

    Returns:
        list of SMILES strings
    """
    print(f"Loading {split} data from {csv_path}...")
    df = pd.read_csv(csv_path)

    if split == 'test_scaffolds':
        split_name = 'test_scaffolds'
    else:
        split_name = split

    data = df[df['SPLIT'] == split_name]['SMILES'].tolist()
    print(f"Loaded {len(data)} molecules for {split}")
    return data


def get_comparison_config(n_batch=256, lr=1e-3):
    """
    è·å–CharRNNé…ç½®

    ä¸diffusionå¯¹æ¯”çš„å…³é”®å‚æ•°:
    - å­¦ä¹ ç‡: ä¿æŒ1e-3 (CharRNNéœ€è¦è¾ƒé«˜å­¦ä¹ ç‡)
    - Dropout: 0.1 (ä¸diffusionå¯¹é½)
    - Batch size: 256 (æŠ˜ä¸­å€¼)
    - è®­ç»ƒæ­¥æ•°: ~30k
    """
    # ä½¿ç”¨MOSESé»˜è®¤parseråˆ›å»ºåŸºç¡€é…ç½®
    parser = get_parser()
    config = parser.parse_args([])

    # ========== CharRNNå‚æ•°è®¾ç½® ==========

    # æ¨¡å‹æ¶æ„
    config.num_layers = 3              # 3å±‚LSTM (MOSESæ ‡å‡†)
    config.hidden = 768                # éšè—å±‚ç»´åº¦ (MOSESæ ‡å‡†)
    config.dropout = 0.1               # âœ… é™ä½è‡³ä¸diffusionå¯¹é½ (åŸ0.2)

    # è®­ç»ƒå‚æ•°
    config.n_batch = n_batch
    config.lr = lr                     # å­¦ä¹ ç‡ (CharRNNé»˜è®¤1e-3)

    # å­¦ä¹ ç‡è°ƒåº¦
    config.step_size = 10              # æ¯10ä¸ªepochè¡°å‡
    config.gamma = 0.5                 # è¡°å‡å› å­0.5

    # è®¡ç®—è®­ç»ƒepochsä»¥è¾¾åˆ°~30k steps
    # æ•°æ®é‡1.58M / batch_size = steps_per_epoch
    # éœ€è¦: 30000 / steps_per_epoch epochs
    # ä¾‹: batch=256 -> 1.58M/256=6172 steps/epoch -> 30k/6172â‰ˆ5 epochs
    # ä½†CharRNNé€šå¸¸éœ€è¦æ›´å¤šepochsæ”¶æ•›ï¼Œå»ºè®®10-15 epochs
    config.train_epochs = 10           # è®­ç»ƒ10ä¸ªepoch

    # å…¶ä»–
    config.n_workers = 4
    config.n_jobs = 1

    return config


def main():
    parser = argparse.ArgumentParser(description='Train CharRNN Baseline for Comparison with Diffusion')

    # æ•°æ®é€‰é¡¹
    parser.add_argument('--use_moses2', action='store_true',
                        help='Use moses2.csv instead of MOSES official dataset')
    parser.add_argument('--moses2_path', type=str, default='./data/moses2.csv',
                        help='Path to moses2.csv')

    # è®­ç»ƒå‚æ•°
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='Device to use (cuda:0 or cpu)')
    parser.add_argument('--n_batch', type=int, default=256,
                        help='Batch size (128/256/512, original CharRNN=64)')
    parser.add_argument('--lr', type=float, default=1e-3,
                        help='Learning rate (CharRNN default=1e-3, diffusion=1e-4)')
    parser.add_argument('--seed', type=int, default=102,
                        help='Random seed (use 102 to align with diffusion)')

    # æ¨¡å‹ä¿å­˜è·¯å¾„
    parser.add_argument('--save_dir', type=str, default='./checkpoints/charrnn_baseline',
                        help='Directory to save model checkpoints')
    parser.add_argument('--log_file', type=str, default='./checkpoints/charrnn_baseline/log.txt',
                        help='Log file path')

    args = parser.parse_args()

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        # è®¾ç½®cuDNNé…ç½®
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.benchmark = True
        print("âœ… cuDNN benchmark mode enabled")

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    # è·å–é…ç½®
    config = get_comparison_config(n_batch=args.n_batch, lr=args.lr)
    config.log_file = args.log_file
    config.model_save = os.path.join(args.save_dir, 'model.pt')
    config.config_save = os.path.join(args.save_dir, 'config.pt')
    config.vocab_save = os.path.join(args.save_dir, 'vocab.pt')

    # åŠ è½½æ•°æ®
    print("\n" + "="*60)
    print("Loading Dataset")
    print("="*60)

    if args.use_moses2:
        train_data = load_moses2_data(args.moses2_path, 'train')
        test_data = load_moses2_data(args.moses2_path, 'test')
    else:
        print("Loading MOSES official dataset...")
        train_data = moses.get_dataset('train')
        test_data = moses.get_dataset('test')
        print(f"Train: {len(train_data)}, Test: {len(test_data)}")

    # æ‰“å°é…ç½®å¯¹æ¯”
    print("\n" + "="*60)
    print("CharRNN Configuration")
    print("="*60)
    print(f"{'Parameter':<25} {'Value':<20} {'Note':<20}")
    print("-"*65)
    print(f"{'Model':<25} {'LSTM':<20} {'Character-level':<20}")
    print(f"{'Hidden Size':<25} {config.hidden:<20} {'MOSES standard':<20}")
    print(f"{'Num Layers':<25} {config.num_layers:<20} {'MOSES standard':<20}")
    print(f"{'Batch Size':<25} {config.n_batch:<20} {'Original: 64':<20}")
    print(f"{'Learning Rate':<25} {config.lr:<20} {'CharRNN standard':<20}")
    print(f"{'Dropout':<25} {config.dropout:<20} {'âœ… = diffusion 0.1':<20}")
    print(f"{'Seed':<25} {args.seed:<20} {'âœ… = diffusion 102':<20}")

    # è®¡ç®—è®­ç»ƒæ­¥æ•°
    steps_per_epoch = len(train_data) // config.n_batch
    total_steps = steps_per_epoch * config.train_epochs
    target_steps = 30000

    print(f"{'Steps per Epoch':<25} {steps_per_epoch:<20}")
    print(f"{'Total Epochs':<25} {config.train_epochs:<20}")
    print(f"{'Total Steps':<25} {total_steps:<20} {f'Target: {target_steps}':<20}")
    print("-"*65)

    if total_steps < target_steps * 0.8:
        print(f"âš ï¸  Warning: Total steps ({total_steps}) < target ({target_steps})")
        print(f"   Consider increasing train_epochs to {int(target_steps/steps_per_epoch) + 1}")

    # åˆ›å»ºæ¨¡å‹
    print("\n" + "="*60)
    print("Initializing Model")
    print("="*60)

    trainer = CharRNNTrainer(config)
    vocab = trainer.get_vocabulary(train_data)
    model = CharRNN(vocab, config).to(args.device)

    print(f"Vocabulary size: {len(vocab)}")
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    # ä¿å­˜é…ç½®å’Œè¯æ±‡è¡¨
    torch.save(config, config.config_save)
    torch.save(vocab, config.vocab_save)
    print(f"\nâœ… Config saved to {config.config_save}")
    print(f"âœ… Vocab saved to {config.vocab_save}")

    # è®­ç»ƒ
    print("\n" + "="*60)
    print("Starting Training")
    print("="*60)
    print(f"Device: {args.device}")

    # æ‰“å°GPUä¿¡æ¯ï¼ˆå¦‚æœä½¿ç”¨CUDAï¼‰
    if args.device.startswith('cuda') and torch.cuda.is_available():
        gpu_id = int(args.device.split(':')[1]) if ':' in args.device else 0
        print(f"GPU Name: {torch.cuda.get_device_name(gpu_id)}")
        print(f"GPU Memory: {torch.cuda.get_device_properties(gpu_id).total_memory / 1024**3:.1f} GB")
        print(f"GPU Memory Allocated: {torch.cuda.memory_allocated(gpu_id) / 1024**2:.1f} MB")

    print(f"Batch size: {config.n_batch}")
    print(f"Learning rate: {config.lr}")
    print(f"Total epochs: {config.train_epochs}")
    print(f"Expected total steps: ~{total_steps}")
    print("="*60 + "\n")

    try:
        model = trainer.fit(model, train_data, val_data=test_data)

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(args.save_dir, 'model_final.pt')
        torch.save(model.state_dict(), final_model_path)
        print(f"\nâœ… Final model saved to {final_model_path}")

    except KeyboardInterrupt:
        print("\nâš ï¸  Training interrupted by user")

    except RuntimeError as e:
        print(f"\nâŒ Training failed with error: {e}")
        if "CUDA" in str(e) or "out of memory" in str(e):
            print("\nğŸ’¡ è§£å†³å»ºè®®:")
            print("1. é™ä½batch size: --n_batch 128 æˆ– --n_batch 64")
            print("2. æ¸…ç†GPUç¼“å­˜: nvidia-smi æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ")
            print("3. å°è¯•ä½¿ç”¨CPU: --device cpu")
            print(f"\nå½“å‰é…ç½®: batch_size={config.n_batch}, device={args.device}")
        raise

    except Exception as e:
        print(f"\nâŒ Training failed with error: {e}")
        raise

    print("\n" + "="*60)
    print("Training Complete!")
    print("="*60)
    print(f"\nModel checkpoints saved in: {args.save_dir}")
    print(f"Log file: {config.log_file}")
    print("\nNext steps:")
    print("1. Generate samples: python scripts/sample.py char_rnn --model_load ...")
    print("2. Evaluate metrics: python scripts/eval.py --gen_path ... --ref_path ...")


if __name__ == '__main__':
    main()
