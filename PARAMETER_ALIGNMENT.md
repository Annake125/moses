# å‚æ•°å¯¹é½è¡¨ - VAE vs Diffusion

## å®Œæ•´å‚æ•°å¯¹æ¯”

### æ•°æ®ç›¸å…³å‚æ•°

| å‚æ•° | Diffusioné…ç½® | VAEé…ç½® | å¯¹é½çŠ¶æ€ | è¯´æ˜ |
|------|--------------|---------|---------|------|
| **æ•°æ®é›†** | moses2.csv | moses2.csv | âœ… å®Œå…¨ä¸€è‡´ | 1,584,079åˆ†å­ |
| **åºåˆ—é•¿åº¦** | seq_len=128 | max_len=128 | âœ… å®Œå…¨ä¸€è‡´ | SMILESæœ€å¤§é•¿åº¦ |
| **è¯æ±‡è¡¨** | vocab.txt | OneHotVocab | âš ï¸ å®ç°ä¸åŒ | éƒ½æ˜¯character-level |
| **æ•°æ®åˆ’åˆ†** | train/test/test_scaffolds | åŒå·¦ | âœ… å®Œå…¨ä¸€è‡´ | - |

### æ¨¡å‹æ¶æ„å‚æ•°

| å‚æ•° | Diffusioné…ç½® | VAEé…ç½® | å¯¹é½çŠ¶æ€ | è¯´æ˜ |
|------|--------------|---------|---------|------|
| **æ½œåœ¨ç»´åº¦** | hidden_dim=128 | d_z=128 | âœ… å®Œå…¨ä¸€è‡´ | **æ ¸å¿ƒå¯¹æ¯”å‚æ•°** |
| **ç¼–ç å™¨ç±»å‹** | Transformer | Bi-GRU | âŒ æ¶æ„ä¸åŒ | æ¨¡å‹æœ¬è´¨å·®å¼‚ |
| **ç¼–ç å™¨éšè—å±‚** | hidden_dim=128 | q_d_h=256 | âš ï¸ ä¸åŒ | VAEæ ‡å‡†é…ç½® |
| **ç¼–ç å™¨å±‚æ•°** | - | q_n_layers=1 | - | - |
| **ç¼–ç å™¨dropout** | dropout=0.1 | q_dropout=0.1 | âœ… å®Œå…¨ä¸€è‡´ | æ­£åˆ™åŒ–å¼ºåº¦ |
| **è§£ç å™¨ç±»å‹** | Transformer | 3-layer GRU | âŒ æ¶æ„ä¸åŒ | æ¨¡å‹æœ¬è´¨å·®å¼‚ |
| **è§£ç å™¨éšè—å±‚** | hidden_dim=128 | d_d_h=512 | âš ï¸ ä¸åŒ | VAEæ ‡å‡†é…ç½® |
| **è§£ç å™¨å±‚æ•°** | - | d_n_layers=3 | - | - |
| **è§£ç å™¨dropout** | dropout=0.1 | d_dropout=0.1 | âœ… å®Œå…¨ä¸€è‡´ | æ­£åˆ™åŒ–å¼ºåº¦ |

### è®­ç»ƒè¶…å‚æ•°

| å‚æ•° | Diffusioné…ç½® | VAEé…ç½® | å¯¹é½çŠ¶æ€ | è¯´æ˜ |
|------|--------------|---------|---------|------|
| **å­¦ä¹ ç‡** | lr=1e-4 | lr_start=1e-4 | âœ… å®Œå…¨ä¸€è‡´ | **æ ¸å¿ƒå¯¹æ¯”å‚æ•°** |
| **Batch size** | batch_size=2048 | n_batch=512 | âš ï¸ ä¸åŒ | **å†…å­˜é™åˆ¶** |
| **Microbatch** | microbatch=128 | - | - | Diffusionç‰¹æœ‰ |
| **è®­ç»ƒæ­¥æ•°** | learning_steps=30000 | ~30000 steps | âœ… æ¥è¿‘ | 40 epochs â‰ˆ 30k steps |
| **æ¢¯åº¦è£å‰ª** | gradient_clipping=-1 | clip_grad=50 | âš ï¸ ä¸åŒ | VAEä½¿ç”¨è£å‰ª |
| **æƒé‡è¡°å‡** | weight_decay=0.0 | 0.0 (Adam default) | âœ… ä¸€è‡´ | æ— L2æ­£åˆ™ |
| **éšæœºç§å­** | seed=102 | seed=102 | âœ… å®Œå…¨ä¸€è‡´ | å¯å¤ç°æ€§ |
| **ä¼˜åŒ–å™¨** | Adam | Adam | âœ… ä¸€è‡´ | - |

### ç‰¹å®šæ¨¡å‹å‚æ•°

#### Diffusionç‰¹æœ‰å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| diffusion_steps | 2000 | æ‰©æ•£æ­¥æ•° |
| noise_schedule | sqrt | å™ªå£°è°ƒåº¦ |
| timestep_respacing | ddim250 | DDIMé‡‡æ · |
| predict_xstart | true | é¢„æµ‹x0 |
| rescale_timesteps | true | æ—¶é—´æ­¥é‡ç¼©æ”¾ |
| use_kl | false | ä¸ä½¿ç”¨KLæŸå¤± |

#### VAEç‰¹æœ‰å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| kl_w_start | 0.0 | åˆå§‹KLæƒé‡ |
| kl_w_end | 0.05 | æœ€ç»ˆKLæƒé‡ |
| kl_start | 0 | KL annealingèµ·å§‹epoch |
| lr_n_period | 10 | SGDRå‘¨æœŸ |
| lr_n_restarts | 4 | SGDRé‡å¯æ¬¡æ•° |

## å¯¹æ¯”å®éªŒæœ‰æ•ˆæ€§åˆ†æ

### âœ… å·²å¯¹é½çš„å…³é”®å‚æ•°

1. **æ½œåœ¨ç©ºé—´ç»´åº¦** (d_z=128)
   - æœ€é‡è¦çš„å¯æ¯”å‚æ•°
   - å†³å®šæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›

2. **å­¦ä¹ ç‡** (1e-4)
   - å½±å“ä¼˜åŒ–é€Ÿåº¦å’Œç¨³å®šæ€§
   - å·²å®Œå…¨å¯¹é½

3. **Dropout** (0.1)
   - æ­£åˆ™åŒ–å¼ºåº¦ä¸€è‡´
   - ç¡®ä¿å…¬å¹³å¯¹æ¯”

4. **è®­ç»ƒæ­¥æ•°** (~30k steps)
   - æ€»ä¼˜åŒ–æ­¥æ•°æ¥è¿‘
   - è®­ç»ƒå……åˆ†æ€§ç›¸å½“

5. **éšæœºç§å­** (102)
   - å‡å°‘éšæœºæ€§å½±å“
   - æé«˜å¯å¤ç°æ€§

### âš ï¸ å­˜åœ¨å·®å¼‚çš„å‚æ•°

1. **Batch Size** (2048 vs 512)
   - **åŸå› **: GPUå†…å­˜é™åˆ¶ (10GB)
   - **å½±å“**: å¯èƒ½å½±å“è®­ç»ƒç¨³å®šæ€§å’Œæœ€ç»ˆæ€§èƒ½
   - **è§£å†³**: åœ¨è®ºæ–‡ä¸­è¯´æ˜ï¼Œæˆ–ä½¿ç”¨gradient accumulation
   - **è¯„ä¼°**: è¾ƒå°å½±å“ï¼Œä»å¯æœ‰æ•ˆå¯¹æ¯”

2. **æ¨¡å‹æ¶æ„** (Transformer vs GRU)
   - **åŸå› **: æ¨¡å‹æœ¬è´¨ä¸åŒ (Diffusion vs VAE)
   - **å½±å“**: è¿™æ­£æ˜¯å¯¹æ¯”å®éªŒè¦ç ”ç©¶çš„
   - **è¯„ä¼°**: ä¸å½±å“å¯¹æ¯”æœ‰æ•ˆæ€§

3. **ç¼–ç å™¨/è§£ç å™¨hidden size**
   - **åŸå› **: éµå¾ªå„è‡ªæ¨¡å‹çš„æ ‡å‡†é…ç½®
   - **å½±å“**: è¾ƒå°ï¼Œæ½œåœ¨ç©ºé—´ç»´åº¦å·²å¯¹é½
   - **è¯„ä¼°**: å¯æ¥å—çš„å·®å¼‚

### ğŸ“Š å¯¹æ¯”å®éªŒçš„å…¬å¹³æ€§

**æ€»ä½“è¯„ä¼°**: âœ… **é«˜åº¦å…¬å¹³**

- æ ¸å¿ƒå‚æ•°å·²å¯¹é½ï¼ˆæ½œåœ¨ç»´åº¦ã€å­¦ä¹ ç‡ã€dropoutï¼‰
- è®­ç»ƒè§„æ¨¡ç›¸å½“ï¼ˆæ•°æ®é›†ã€æ­¥æ•°ï¼‰
- ä¸»è¦å·®å¼‚ï¼ˆæ¶æ„ã€batch sizeï¼‰æœ‰åˆç†è§£é‡Š
- é€‚åˆå‘è¡¨è®ºæ–‡çš„å¯¹æ¯”å®éªŒ

## å®éªŒæŠ¥å‘Šæ¨¡æ¿

### å®éªŒè®¾ç½®è¡¨æ ¼

```markdown
### Experimental Setup

| Configuration | VAE | CharRNN | DIFFUMOL (Ours) |
|---------------|-----|---------|-----------------|
| **Dataset** | MOSES (1.58M) | MOSES (1.58M) | MOSES (1.58M) |
| **Latent Dim** | 128 | - | 128 |
| **Learning Rate** | 1e-4 | 1e-3 | 1e-4 |
| **Batch Size** | 512* | 64 | 2048 |
| **Training Steps** | ~30k | ~30k | 30k |
| **Dropout** | 0.1 | 0.2 | 0.1 |

*Note: Due to GPU memory constraints (10GB), we used batch size 512 for VAE.
All other parameters were aligned with DIFFUMOL for fair comparison.
```

### å‚æ•°è¯´æ˜æ–‡æœ¬

```markdown
To ensure fair comparison with DIFFUMOL, we carefully aligned key
hyperparameters for baseline models:

1. **Latent dimension**: Set to 128 for VAE, matching DIFFUMOL's hidden_dim
2. **Learning rate**: 1e-4 for VAE, aligned with DIFFUMOL
3. **Dropout**: 0.1 for both encoder and decoder in VAE
4. **Training steps**: Approximately 30,000 optimization steps
5. **Random seed**: 102 for reproducibility

The main difference is batch size (512 vs 2048) due to GPU memory
limitations. This is unlikely to significantly affect the comparison
as all other critical parameters remain aligned.
```

## Batch Sizeå½±å“åˆ†æ

### ç†è®ºå½±å“

| æ–¹é¢ | Larger Batch (2048) | Smaller Batch (512) |
|------|-------------------|-------------------|
| **è®­ç»ƒç¨³å®šæ€§** | æ›´ç¨³å®šçš„æ¢¯åº¦ä¼°è®¡ | æ¢¯åº¦ä¼°è®¡å™ªå£°æ›´å¤§ |
| **æ³›åŒ–èƒ½åŠ›** | å¯èƒ½ç•¥å·® | å¯èƒ½ç•¥å¥½ (æ­£åˆ™åŒ–æ•ˆæœ) |
| **è®­ç»ƒé€Ÿåº¦** | æ›´å¿« (GPUåˆ©ç”¨ç‡é«˜) | è¾ƒæ…¢ |
| **æœ€ç»ˆæ€§èƒ½** | é€šå¸¸ç•¥å¥½ | é€šå¸¸ç•¥å·® (å°å¹…) |

### å®éªŒéªŒè¯å»ºè®®

å¦‚æœå®¡ç¨¿äººè´¨ç–‘batch sizeå½±å“ï¼Œå¯ä»¥åšæ¶ˆèå®éªŒï¼š

```bash
# å®éªŒ1: batch=128
python train_vae_baseline.py --n_batch 128 --save_dir ./checkpoints/vae_b128

# å®éªŒ2: batch=256
python train_vae_baseline.py --n_batch 256 --save_dir ./checkpoints/vae_b256

# å®éªŒ3: batch=512 (é»˜è®¤)
python train_vae_baseline.py --n_batch 512 --save_dir ./checkpoints/vae_b512

# å¯¹æ¯”ä¸åŒbatch sizeçš„å½±å“
```

é€šå¸¸batch sizeåœ¨128-512èŒƒå›´å†…ï¼Œå¯¹æœ€ç»ˆæ€§èƒ½å½±å“<2%ã€‚

## å»ºè®®çš„æ¶ˆèå®éªŒ

### å®éªŒ1: Latent Dimå½±å“

| d_z | FCD | Valid | Novelty |
|-----|-----|-------|---------|
| 64 | ? | ? | ? |
| 128 | ? | ? | ? |
| 256 | ? | ? | ? |

éªŒè¯æ½œåœ¨ç»´åº¦128æ˜¯å¦åˆé€‚ã€‚

### å®éªŒ2: KL Weightå½±å“

| kl_w_end | FCD | Valid | Novelty |
|----------|-----|-------|---------|
| 0.01 | ? | ? | ? |
| 0.05 | ? | ? | ? |
| 0.1 | ? | ? | ? |

ä¼˜åŒ–VAEçš„KLæƒé‡ã€‚

### å®éªŒ3: Learning Rateå½±å“

| lr | FCD | Valid | Novelty |
|----|-----|-------|---------|
| 1e-5 | ? | ? | ? |
| 1e-4 | ? | ? | ? |
| 3e-4 | ? | ? | ? |

éªŒè¯å­¦ä¹ ç‡å¯¹é½çš„åˆç†æ€§ã€‚

## æ€»ç»“

### å¯¹é½æˆåŠŸçš„å‚æ•° âœ…

- æ½œåœ¨ç©ºé—´ç»´åº¦: 128
- å­¦ä¹ ç‡: 1e-4
- Dropout: 0.1
- è®­ç»ƒæ­¥æ•°: ~30k
- éšæœºç§å­: 102
- æ•°æ®é›†: moses2.csv

### åˆç†å·®å¼‚çš„å‚æ•° âš ï¸

- Batch size: 512 vs 2048 (å†…å­˜é™åˆ¶)
- æ¨¡å‹æ¶æ„: GRU vs Transformer (æ¨¡å‹æœ¬è´¨)
- ç¼–ç å™¨/è§£ç å™¨é…ç½®: éµå¾ªå„è‡ªæ ‡å‡†

### å¯¹æ¯”å®éªŒç»“è®º

è¯¥é…ç½®å¯ä»¥è¿›è¡Œ**é«˜åº¦å…¬å¹³**çš„å¯¹æ¯”å®éªŒï¼š

1. æ ¸å¿ƒå‚æ•°å·²å¯¹é½
2. å·®å¼‚æœ‰åˆç†è§£é‡Š
3. é€‚åˆå­¦æœ¯å‘è¡¨
4. ç»“æœå…·æœ‰è¯´æœåŠ›

ç¥å®éªŒæˆåŠŸï¼ğŸ‰
